<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta content="text/html;charset=utf-8" http-equiv="Content-Type">
<style type="text/css">
table {
   border-collapse: collapse;
   border-width: 1px;
   border-spacing: 1px;
   border-color: transparent;
   margin: 16px 0;
   width: 100%;
}
th {
   background-color: #bbb; color: white;
}
td, th {
   border-style: solid;
   border-color: black;
   border-width: 1px;
   padding: 0 6px;
}
td p:first-child, th p:first-child {
   margin-top: 3px;
}
td p:last-child, th p:last-child {
   margin-bottom: 3px;
}

.smarkdoc {
  margin-left: 42px; margin-right: 42px;
  font-size: 13px;
  font-family: 'Lucida Grande', Geneva, Helvetica, Arial, sans-serif;
}

h1, h2, h3 { color: #3c4c6c; }
h1 {
  text-align: center;
  font-size: 200%;
/*    margin-left: -30px; */
  clear: both;
}
h2 {
  font-size: 160%;
  margin: 32px -40px 24px -42px;
  padding: 3px 24px 8px;
  border-bottom: 2px solid #5088c5;
  clear: both;
}
h3 {
  font-size: 130%;
  margin: 20px -4px 10px;
  padding: 4px;
  clear: both;
}
h4 {
  font-size: 110%;
  margin: 2em 0 1em;
}

pre {
  font-size: 90%;
  background-color: #f0f0f4; padding: 6px; border: 1px solid #d0d0ee;
  font-family: "Courier New", "Lucida Console", "Monaco", monospace;
}

.pre {
  font-size: 90%;
  padding: 6px;
  background-color: #f0f0f4;
  font-family: "Courier New", "Lucida Console", "Monaco", monospace;
}

code {
  font-size: 90%;
  font-family: "Courier New", "Lucida Console", "Monaco", monospace;
}

h3 code {
  font-size: 100%;
}

p {
  margin: 0.8em 0;
}
ul, ol {
  margin: 1em 0 1em 3em; padding: 0;
}
div.indent {
  margin: 0 3em;
}

a[href] {
  text-decoration: none;
  color: #2020b0;
}
a[href]:hover {
  border-bottom: 1px dotted #2030d0;
}

/* Smark Users Guide */

.codebox {
  padding: 0 1px;  margin-right:1px;
  border:1px solid #d0d0ee;
  background-color: #f0f0f4;
  font-weight: bold;
  font-family: "Courier New", "Lucida Console", "Monaco", monospace;
}

/* ================ Smark-specific classes ================ */

.indent {
  margin: 0 3em;
}

/*
|| Floats affect text flow but not block boundaries, so graphics in a DIV
|| would overlap floats if not for "clear: both"
*/
.diagram {
  margin: 18px 0;
  clear: both;
}

/* ASCII Art */

.art {
  margin-right: auto; margin-left: auto; /* center */
  font-family: Arial, Verdana, "Lucida Console", Monaco, monospace;
  font-weight: bold;
}
.art * {
   border-color: #543;
}
.art .dline, .art .drect {
   border-style: dotted;
}
.art .rect {
   -webkit-box-shadow: 0.2em 0.2em 0.3em rgba(0,0,0,0.3);
   -moz-box-shadow: 0.2em 0.2em 0.3em rgba(0,0,0,0.3);
   box-shadow: 0.2em 0.2em 0.2em #875;
   background-color: #f9faf4; /* #fafff4; #f8f8ec;  */
}
.art .nofx {
   background-color: #f9faf4;
}
.art .round {
   border-radius: 0.6em;
   -webkit-border-radius: 0.6em;
   -moz-border-radius: 0.6em;
}

/* .art .line {  -webkit-box-shadow: 0.1em 0.1em 0.2em rgba(0,0,0,0.3); } */

/* Sequence Charts */

.msc {
   font: 11px Verdana, Monaco, "Lucida Console";
   margin-left: auto; margin-right: auto;
   background-color: white;
   /* border: 1px solid #555; */  /* Useful for non-white pages */
}

/* Table of Contents */

.tocLevel {
  margin-left: 2em;
  font-weight: normal;
}
.tocLevel .tocLevel {
  font-size: 90%; /* ...of inherited font size */
  line-height: 150%; /* ...of font size */
}
.toc > .tocLevel {
  font-weight: bold;
  margin: 0.5em 0
}
.toc {
  column-count: 2; column-gap: 2em;
  -moz-column-count: 2; -moz-column-gap: 2em;
  -webkit-column-count: 2; -webkit-column-gap: 2em;
}

/* ordinary text content is in P elements */

td p:first-child, th p:first-child {
   margin-top: 3px;
}
td p:last-child, th p:last-child {
   margin-bottom: 3px;
}
li p:only-child {
  margin-top: 0;
  margin-bottom: 0;
}

/* ================ Print ================ */

@media print {

  @page {
    margin: 0.75in 0.75in;
    size: Letter;
    @bottom {
      content: counter(page);
      vertical-align: top;
      padding-top: 1em;
    }
  }
  h1 { text-align: center;
       margin: 3in 0 20px; }
  h2 { page-break-before: always; }
  h2 { string-set: section content() }
  .toc { margin: 3em -2em }
  .toc a::after {
     font-size: 10px;
     content: leader(' . ') "  " target-counter(attr(href), page);
  }
  table { page-break-inside: avoid; }
}

/* ================  Layout  ================ */
/*
 *  +------------------------+
 *  |         #header        |
 *  +----------+-------------+
 *  | #sidebar |  #content   |
 *  |          |             |
 *  +----------+-------------+
 *
 * CSS padding, border width, and border style (!) affect the actual height
 * (and in turn layout).
 */

#header {
  position: fixed;
  top: 0px;
  height: 32px;
  left: 0px;
  width: 100%;
  padding: 10px 10px 0 0;
}
#sidebar {
  position: fixed;
  top: 42px;
  bottom: 0px;
  left: 0px;
  min-width: 180px;
  overflow: auto;
  border: 1px solid transparent;
  border-width: 0 1px 0 1px;
  padding: 0px 5px 0px 5px;
}
#content {
  position: fixed;
  top: 60px;
  left: 200px;
  bottom: 0px;
  right: 0px;
  overflow: auto;
  -webkit-overflow-scrolling: touch;
  padding: 10px 20px;
  padding-top: 0;
}

/* ================  Styles  ================ */


body {
  font-family: "Lucida Grande", Helvetica, Arial, sans-serif;
  font-size: 16px;
}

#header {
  color: #fff;
  background: #555;
  text-align: center;
  font-size: 25px;
}

#sidebar {
  color: #000;
  background: #eee;
  border-right: 1px solid #bbb;
  text-align: left;
  font-size: 12px;
  line-height: 50%;
}

#sidebar h1 {
  margin: 0 0 0 0;
  border-left: 5px solid transparent;
  text-align: left;
  font-size: 12px;
  /*text-shadow: #fff 1px 0px;*/
  line-height: 1%;
}

#sidebar h2 {
  margin: 2px 0 8px 0;
  border-left: 5px solid transparent;
  text-align: center;
  font-size: 12px;
  /*text-shadow: #fff 1px 0px;*/
  line-height: 1%;
}



#content {
  margin: 0;
  font-size: 13px;
  line-height: 160%;
}

#content h1, #content h2 {
  border-bottom: 2px solid;
  font-size: 1.8em;
  font-weight: normal;
  margin: 2.0em 0px 1.3em 0px;
  padding-bottom: 0.6em;
  text-align: left;
}

#content h3 {
  color: #242220;
  font-size: 1.4em;
  font-weight: normal;
  margin: 2em 0px 0.8em 0px;
  text-shadow: #FFFFFF 0px 1px 1px;
}
#content h4 {
  font-size: 1.2em;
  font-weight: normal;
  margin: 2em 0px 0.5em 0px;
  text-shadow: #FFFFFF 0px 1px 1px;
}

a[href] {
  color: #05c;
  text-decoration: none;
}

#sidebar a {
  /*text-shadow:  1px 1px 2px #fff, -1px -1px #ddd;*/
  line-height: 40%;
}

pre, code {
  font-family: "Courier New", "Lucida Console", "Monaco", monospace;
  font-family: "Monaco", monospace;  font-size: 90%;
  background-color: #f8f8fa;
  border: 1px solid #e4e4ee;
  -webkit-border-radius: 2px;
  -moz-border-radius: 2px;
  border-radius: 2px;
  padding: 1px 0 0 1px;
}

pre {
  padding: 2px 4px;
}

table {
   border-collapse: collapse;
   border-width: 1px;
   border-spacing: 1px;
   border-color: transparent;
   margin: 16px 0;
   width: 100%;
}
th {
   background-color: #bbb; color: white;
}
td, th {
   border-style: solid;
   border-color: black;
   border-width: 1px;
   padding: 0 6px;
}

/* Highlight currently-selected sidebar link */

#sidebar a.thisfile {
  color: #557;
}

/* indentation */

#content {
   padding-left: 60px;
}
#content h1, 
#content h2, 
#content h3, h4 {
    margin-left: -30px;
}

h3 > code {
    font-size: 80%;
}

/* ================ Smark-specific classes ================ */

.indent {
  margin: 0 3em;
}

/*
|| Floats affect text flow but not block boundaries, so graphics in a DIV 
|| would overlap floats if not for "clear: both"
*/
.diagram {
  margin: 18px 0;
  clear: both;
}

/* ASCII Art */

.art {
  margin-right: auto; margin-left: auto; /* center */
  font-family: Arial, Verdana, "Lucida Console", Monaco, monospace;
  font-weight: bold;
}
.art * {
   border-color: #543;
}
.art .dline, .art .drect {
   border-style: dotted;
}
.art .rect {
   -webkit-box-shadow: 0.2em 0.2em 0.3em rgba(0,0,0,0.3);
   -moz-box-shadow: 0.2em 0.2em 0.3em rgba(0,0,0,0.3);
   box-shadow: 0.2em 0.2em 0.2em #875;
   background-color: #f9faf4; /* #fafff4; #f8f8ec;  */
}
.art .nofx {
   background-color: #f9faf4;
}
.art .round {
   border-radius: 0.6em;
   -webkit-border-radius: 0.6em;
   -moz-border-radius: 0.6em;
}

/* Sequence Charts */

.msc {
   font: 11px Verdana, Monaco, "Lucida Console"; 
   margin-left: auto; margin-right: auto;
   background-color: white;
   border: 1px solid #555;
}

/* Table of Contents */

.tocLevel {
  margin-left: 2em;
  font-weight: normal;
}
.tocLevel .tocLevel {
  font-size: 90%; /* ...of inherited font size */
  line-height: 150%; /* ...of font size */
}
/*
.toc > .tocLevel {
  font-weight: bold;
  margin: 0.5em 0
}
*/

.toc {
  column-count: 1; column-gap: 2em;
  -moz-column-count: 1; -moz-column-gap: 2em;
  -webkit-column-count: 1; -webkit-column-gap: 2em; 
   alternate: column-width: 235px; column-rule-width: 5px;
}


.columns {
  column-count: 2; column-gap: 2em;
  -moz-column-count: 2; -moz-column-gap: 2em;
  -webkit-column-count: 2; -webkit-column-gap: 2em; p
}

/* ordinary text content is in P elements */

td p:first-child, th p:first-child {
   margin-top: 3px;
}
td p:last-child, th p:last-child {
   margin-bottom: 3px;
}
li p:only-child {
  margin-top: 0;
  margin-bottom: 0;
}


/* ================ Print ================ */

@media print {

  #header, #content { position: static; }
  #sidebar { display: none; }

  @page {
    margin: 0.75in 0.75in;
    size: Letter;
    @bottom {
      content: counter(page);
      vertical-align: top;
      padding-top: 1em;
    }
  }
  h1 { text-align: center;
       margin: 1in 0 1in; }
  h2 { page-break-before: always; }
  h2 { string-set: section content() }
  .toc { margin: 3em 0 }
  .toc a::after {
     font-size: 10px;
     content: leader(' . ') "  " target-counter(attr(href), page);
  }
  table { page-break-inside: avoid; }
}


</style><style type="text/css">
.search { right: 20pt; position: fixed; top: 5pt }

</style><title>Camera streaming</title>
</head><body>
<div class="smarkdoc"><div id="header">Hexagon SDK 3.5.4</div><div id="sidebar"><top><img src="../images/sidebar_top.jpg"></top><script src="../scripts/post.js" type="text/javascript"></script><form class="search" id="searchForm"><input id="searchquery" name="q" onkeydown="postFunctionKeydown(event, true)"><input id="searchButton" onclick="postFunction(true)" type="button" value="Search"></form><p>
<a href="../index.html">Quick start</a>
</p><hr>
<p>
<a href="../feature_matrix.html">Feature Matrix</a>
</p><hr>
<p>
<a href="../hexagon_architecture.html">Hexagon Architecture</a>
</p><hr>
<p>
<a href="../images/Hexagon_Document_Bundle.pdf#page=2881">Hexagon Compiler/Linker</a>
</p><hr>
<p>
<a href="../hexagon_libraries.html">Hexagon Standard Libraries</a>
</p><hr>
<p>
<a href="../images/80-VB419-178_QuRT_User_Guide.pdf">Hexagon RTOS</a>
</p><hr>
<p>
<a href="../images/80-VB419-108_Hexagon_DSP_User_Guide.pdf">Hexagon DSP Programming</a>
</p><hr>
<h3>
<a name="Platforms"></a>Platforms
</h3><p>
<a href="../Platforms_HLOS.html">HLOS</a>
</p><p>
<a href="../Platforms_Simulator.html">Simulator</a>
</p><p>
<a href="../Platforms_Target.html">Target</a>
</p><hr>
<h3>
<a name="Environments"></a>Environments
</h3><p>
<a href="../Environments_Build%20System.html">Build System</a>
</p><p>
<a href="../Environments_Build%20System%20Porting.html">Build System Porting</a>
</p><p>
<a href="../Environments_Hexagon%20IDE.html">Hexagon IDE</a>
</p><hr>
<h3>
<a name="ArchitectureOverview"></a>ArchitectureOverview
</h3><p>
<a href="../HVX/ArchitectureOverview.html">HVX</a>
</p><hr>
<h3>
<a name="Applications"></a>Applications
</h3><p>
<a href="../Audio/Applications.html">Audio</a>
</p><p>
<a href="../Camera%20streaming/Applications.html">Camera streaming</a>
</p><p>
<a href="../Applications_Compute%20offload.html">Compute offload</a>
</p><p>
<a href="../FastCV/Applications_Computer%20Vision.html">Computer Vision</a>
</p><p>
<a href="../Neural%20Networks/Applications.html">Neural Networks</a>
</p><p>
<a href="../Voice/Applications.html">Voice</a>
</p><p>
<a href="../Camera%20streaming/Applications_legacy.html">legacy</a>
</p><hr>
<h3>
<a name="APIs"></a>APIs
</h3><p>
<a href="../APIs_Async%20Message%20Queue.html">Async Message Queue</a>
</p><p>
<a href="../APIs_DSP%20Clk%20&amp;%20Rsrc%20Mgmt.html">DSP Clk &amp; Rsrc Mgmt</a>
</p><p>
<a href="../APIs_Dynamic%20Loading.html">Dynamic Loading</a>
</p><p>
<a href="../APIs_FastRPC.html">FastRPC</a>
</p><hr>
<h3>
<a name="Examples"></a>Examples
</h3><p>
<a href="../Audio/Examples.html">Audio</a>
</p><p>
<a href="../Camera%20streaming/Examples.html">Camera streaming</a>
</p><p>
<a href="../Examples_Common.html">Common</a>
</p><p>
<a href="../Examples_ComputeHVX.html">ComputeHVX</a>
</p><p>
<a href="../Examples_GeneralOverview.html">GeneralOverview</a>
</p><p>
<a href="../Neural%20Networks/Examples.html">Neural Networks</a>
</p><p>
<a href="../Camera%20streaming/Examples_legacy.html">legacy</a>
</p><hr>
<h3>
<a name="Testing"></a>Testing
</h3><p>
<a href="../CAPIv2/Testing_CAPIv2%20Unit%20Tests.html">CAPIv2 Unit Tests</a>
</p><p>
<a href="../Testing_Eclipse%20Unit%20Tests.html">Eclipse Unit Tests</a>
</p><hr>
<h3>
<a name="Debugging"></a>Debugging
</h3><p>
<a href="../Debugging_Connect%20to%20Device.html">Connect to Device</a>
</p><p>
<a href="../Debugging_Exceptions.html">Exceptions</a>
</p><p>
<a href="../Debugging_Message%20Logging.html">Message Logging</a>
</p><p>
<a href="../Debugging_Simulator.html">Simulator</a>
</p><p>
<a href="../Debugging_Target.html">Target</a>
</p><hr>
<h3>
<a name="Tools"></a>Tools
</h3><p>
<a href="../Tools_Hexagon%20Tools%208.3.html">Hexagon Tools 8.3</a>
</p><p>
<a href="../Tools_IDL%20Compiler.html">IDL Compiler</a>
</p><p>
<a href="../Tools_On%20Target%20Profiling.html">On Target Profiling</a>
</p><p>
<a href="../Tools_Scripts.html">Scripts</a>
</p><p>
<a href="../Tools_Signing.html">Signing</a>
</p><p>
<a href="../Tools_UserGuides.html">UserGuides</a>
</p><p>
<a href="../Tools_Utilities.html">Utilities</a>
</p><hr>
<h3>
<a name="FAQ"></a>FAQ
</h3><p>
<a href="../FAQ_Common.html">Common</a>
</p><p>
<a href="../FAQ_Dynamic%20Loading.html">Dynamic Loading</a>
</p><p>
<a href="../FAQ_FastRPC.html">FastRPC</a>
</p><p>
<a href="../FAQ_Hexagon%20IDE.html">Hexagon IDE</a>
</p><hr>
<h3>
<a name="Dependencies"></a>Dependencies
</h3><p>
<a href="../Dependencies_Common.html">Common</a>
</p><hr>
<h3>
<a name="Release%20Notes"></a>Release Notes
</h3><p>
<a href="../Release%20Notes_Common.html">Common</a>
</p><hr>
<h3>
<a name="Support"></a>Support
</h3><p>
<a href="../Support_Contact.html">Contact</a>
</p><center><img src="../images/sidebar_bot.jpg"></center></div><div id="content"><a name="_top_" style="display:block;"></a><h1>
<a name="Camera%20streaming"></a>Camera streaming
</h1><div class="toc"><div class="tocLevel"><a href="#Introduction">Introduction</a></div><div class="tocLevel"><a href="#Camera%20streaming%20overview">Camera streaming overview</a><div class="tocLevel"><a href="#HVX%20streaming%20module">HVX streaming module</a></div><div class="tocLevel"><a href="#HVX%20streaming%20data%20format">HVX streaming data format</a></div><div class="tocLevel"><a href="#HVX%20streaming%20data%20padding/stripping%20support">HVX streaming data padding/stripping support</a></div><div class="tocLevel"><a href="#HVX%20streaming%20frame%20format">HVX streaming frame format</a></div></div><div class="tocLevel"><a href="#Camera%20streaming%20framework%20and%20APIs">Camera streaming framework and APIs</a><div class="tocLevel"><a href="#OEM%20plugin%20API">OEM plugin API</a></div><div class="tocLevel"><a href="#QDSP6%20lib%20API">QDSP6 lib API</a></div></div><div class="tocLevel"><a href="#Communication%20and%20buffers">Communication and buffers</a><div class="tocLevel"><a href="#Receiving%20buffer%20(RX)">Receiving buffer (RX)</a></div><div class="tocLevel"><a href="#Transmission%20buffer%20(TX)">Transmission buffer (TX)</a></div><div class="tocLevel"><a href="#Communication%20buffer%20(CX)">Communication buffer (CX)</a></div></div></div><h2>
<a name="Introduction"></a>Introduction
</h2><p>
<i>Note:</i>
</p><p>
This application note applys to sm8250/sm7250/sm8350.
</p><p>
For other targets such as msm8998, sdm660, sdm485, sm8150, sm7150, sm6125 etc. Please refer to <a href="Applications_legacy.html">Applications_legacy.html</a>.
</p><p>
Camera streaming enables powerful and efficient on-the-fly pixel manipulation of camera sensor data. The streaming module is designed to process pixel data in Bayer domain. It is ideal for camera ISP pre-processing or handling camera sensors with non-conventional Bayer format.
</p><p>
Camera streaming application consists of HVX streaming hardware as well as the software stack that controls it. HVX streaming hardware is integrated as part of Snapdragon SOC on selected chip-sets. The software stack is provided by both Qualcomm camera driver and application developers.
</p><p>
Please see the <a href="Examples.html">Dependencies</a> page for details about requirement.
</p><h2>
<a name="Camera%20streaming%20overview"></a>Camera streaming overview
</h2><h3>
<a name="HVX%20streaming%20module"></a>HVX streaming module
</h3><left><img src="images/Camera_highlevel.png"></left><p>
The IFE is a real time image processing HW core that takes the image stream from the sensor and processes data inline before writing the final data out to DDR memory.
</p><left><img src="images/streaming_IF.png"></left><p>
In streaming mode, the IFE has a set of output ports that are directly connected to the DSP and allows pixel data to be transferred in real time to the DSP L2 cache where it can be processed by firmware implementing the desired image processing algorithms.
</p><p>
The IFE also has a set of input ports that allows the DSP to directly send the pixel stream back to the IFE image processing pipeline for subsequent real time processing. When using HVX streaming mode, the DSP must be able to sustain a throughput that matches the real time pixel rate of the ISP.
</p><p>
There are 4 fixed tap-in/tap-out locations in the IFE which provide flexibility to configure where in the processing pipeline the HVX will be used . Only 1 of the tap-in/tap-out points can be used at a given time and cannot be changed dynamically on the fly. The tap-in/tap-out locations are :
</p><pre>HVX_Tap0: At the beginnig of the IFE.
HVX_Tap1: Before the HDR reconstruction.
HVX_Tap2: After the HDR MAC.
HVX_Tap3: Before White balance/Demosaic.
</pre><h3>
<a name="HVX%20streaming%20data%20format"></a>HVX streaming data format
</h3><p>
The HVX streaming module takes Bayer raw data patterns: RGGB, BGGR, GRBG, GBRG, as well as other Bayer-like pixel data format. It supports 8, 10, 12, 14 bits data.
</p><p>
HVX streaming module will unpack Bayer raw data, and put each pixel/component in a 16-bit mode with configurable as MSB or LSB aligned, or in a 8-bit mode as described below:
</p><left><img src="images/L2_packing.png"></left><h3>
<a name="HVX%20streaming%20data%20padding/stripping%20support"></a>HVX streaming data padding/stripping support
</h3><p>
Input padding is supported by streamer hardware. When a line is received, eight extra pixels may be added to the beginning and end of the line. The added pixels may be zeros or a replication of recent pixels.
</p><left><img src="images/padding.PNG"></left><p>
Output stripping is also supported by streamer hardware. Once enabled, streamer will transmit data offset from location 0 by 8 pixels.
</p><h3>
<a name="HVX%20streaming%20frame%20format"></a>HVX streaming frame format
</h3><p>
A frame sent from camera sensor contains both valid pixels and invalid pixel data. It also includes control strobes such as start-of-frame (SOF), end-of-frame (EOF), start-of-line (SOL), end-of-line (EOL) etc The pixel data between any EOL and following SOL control strobe and the lines between EOF and following SOF control strobes is referred to as invalid pixel data. The Streamer Hardware strips the invalid pixel data along with the control strobes and stores only the active pixel data in the L2$ which will be processed by the DSP. The stripped control strobes will be re-generated at end of QDSP6 process, where pixel data is sent back to ISP's pixel interface.
</p><left><img src="images/hvx_streaming_frame_format.png"></left><h2>
<a name="Camera%20streaming%20framework%20and%20APIs"></a>Camera streaming framework and APIs
</h2><p>
To enable camera HVX streaming feature, camxoverridesettings.txt need to be pushed onto target and reboot the target:
</p><pre style="font-size: 84%">adb root
adb remount
adb shell mkdir -p /vendor/etc/camera
adb shell "echo enableDualIFE=FALSE &gt;&gt; /vendor/etc/camera/camxoverridesettings.txt"
adb shell "echo enableHVXStreaming=1 &gt;&gt; /vendor/etc/camera/camxoverridesettings.txt"
adb reboot
</pre><p>
Camera streaming framework is deeply integrated with Qualcomm camera driver in order to provide accurate timing required by streaming. This framework enables ARM/DSP interaction, HVX and IFE synchronization, as well as integration of QDSP6 custom framework lib and OEM Stub plugin. This diagram gives better understanding of how camera streaming framework works.
</p><left><img src="images/streamerSW_block_diagram.png"></left><p>
The blue blocks are libraries to be implemented by user. They are OEM plugin and QDSP6 lib respectively.
</p><ul type="circle">
<li>
<p>
The OEM plugin runs in Android's user-space driver. This lib provides important information that controls the operations on streaming pixel data by HVX, including sensor configurations, threading control, algorithm coefficients, as well as parameters to be updated at runtime. Application developers are expected to implement this lib using APIs provided by Qualcomm.
</p>
</li><li>
<p>
QDSP6 lib is the core library where developer's own optimized algorithm will run.
</p>
</li>
</ul><h3>
<a name="OEM%20plugin%20API"></a>OEM plugin API
</h3><p>
OEM plugin API and implementation could be updated in Android build release. Please always refer to Android build for latest version. Place to check in Android build:
</p><pre>&lt;platform&gt;/vendor/qcom/proprietary/camx/chi-cdk/vendor/node/hvx
&lt;platform&gt;/vendor/qcom/proprietary/camx/chi-cdk/vendor/topology/qcom
</pre><p>
OEM plugin is responsible for configuring the mode, size, and many other important parameters for camera streaming case. It is also responsible to send QDSP6 per-frame updates on the fly. Algorithm specific information can only be determined by the algorithm developer themselves.
</p><left><img src="images/OEM_CallFlow.png"></left><p>
The OEM Stub Lib is loaded if the topology xml references the property name within the IFE node as shown below:
</p><pre>com.qti.hvx.addconstant
</pre><pre>&lt;Node&gt;
  &lt;NodeName&gt;IFE&lt;/NodeName&gt;
  &lt;NodeId&gt;65536&lt;/NodeId&gt;
  &lt;NodeInstance&gt;IFEInstanceName0&lt;/NodeInstance&gt;
  &lt;NodeInstanceId&gt;0&lt;/NodeInstanceId&gt;
  &lt;NodeProperty&gt;
    &lt;NodePropertyName&gt;NodePropertyCustomLib&lt;/NodePropertyName&gt;
    &lt;NodePropertyId&gt;1&lt;/NodePropertyId&gt;
    &lt;NodePropertyDataType&gt;STRING&lt;/NodePropertyDataType&gt;
    &lt;NodePropertyValue&gt;com.qti.hvx.addconstant&lt;/NodePropertyValue&gt;
  &lt;/NodeProperty&gt;
  &lt;NodeProperty&gt;
    &lt;NodePropertyName&gt;NodePropertyStatsSkipPattern&lt;/NodePropertyName&gt;
    &lt;NodePropertyId&gt;6&lt;/NodePropertyId&gt;
    &lt;NodePropertyDataType&gt;UINT&lt;/NodePropertyDataType&gt;
    &lt;NodePropertyValue&gt;1&lt;/NodePropertyValue&gt;
  &lt;/NodeProperty&gt;
&lt;/Node&gt;
</pre><p>
In order to achieve that, user lib need to be implemented conforming to following API:
</p><p>
<b>Callback Functions:</b>
</p><pre><span style="color: blue">typedef</span> <span style="color: blue">struct</span> CHIISPHVXALGORITHMCALLBACKS
{
        <span style="color: darkgreen">/**
         * HVXInitialize:
         *
         * @brief Allocate oem_data and return to caller
         * @param oem_data double pointer to oem_data, to be
         *             filled by OEM stub
         *
         * @return CDKResultSuccess upon success.
         *
         */</span>
        CDKResult (*pHVXInitialize)(VOID **oem_data);

        <span style="color: darkgreen">/**
         * HVXGetResolutionInfo:
         *
         * @brief  Send Input from ISP and get OEM ouput information
         *
         * @param oem_data  OEM specific private data
         * @param hvx_info  hvx information
         *
         * @return CDKResultSuccess upon success.
         *
         */</span>
        CDKResult(*pHVXGetResolutionInfo)(VOID *oem_data,
                HVXResolutionInfo **res_info);

        <span style="color: darkgreen">/**
         * HVXGetSetHVXInfo:
         *
         * @brief  Send Input from ISP and get OEM ouput information
         *
         * @param oem_data  OEM specific private data
         * @param hvx_info  hvx information
         *
         * @return CDKResultSuccess upon success.
         */</span>
        CDKResult (*pHVXGetSetHVXInfo)(VOID *oem_data,
                HVXGetSetInfo *hvx_info);

        <span style="color: darkgreen">/**
         * HVXSetConfig:
         *
         *  @brief Set sensor output along with Single / dual vfe information
         *
         *  @param oem_data: OEM specific private data
         *  @param lib_config   sensor output info
         *  @param adspConfig  ADSP config handle
         *  @param handle       caller private data to be passed back in
         *              adspConfig_call
         *
         * @return CDKResultSuccess upon success.
         */</span>
        CDKResult (*pHVXSetConfig)(VOID *oem_data,
                HVXConfig*          stubConfig,
                <span style="color: blue">const</span> HVXDSPConfig *adspConfig,
                INT*                handle);

        <span style="color: darkgreen">/**
         * HVXCallbackData
         *
         *  @brief  This method destroys the derived instance of the interface
         *
         *  @param handle     handle
         *  @param RequestID  Input feedback params
         *  @param bufLabel   Buffer label
         *  @param caller_data  caller private data to be passed back in
         *         adspConfig_call
         *
         * @return CDKResultSuccess upon success.
         */</span>
        CDKResult (*pHVXCallbackData)(INT handle,
                HVXIFEType IFEType, UCHAR bufLabel);

        <span style="color: darkgreen">/**
         * HVXExecute
         *
         *  @brief  This method destroys the derived instance of the interface
         *
         *  @param OEMData      OEM specific private data
         *  @param InputParams  Input feedback params
         *  @param ADSPConfig   ADSP config handle
         *  @param handle       caller private data to be passed back in
         *         adspConfig call
         *
         * @return CDKResultSuccess upon success.
         */</span>
        CDKResult (*pHVXExecute)(VOID *oem_data,
                <span style="color: blue">const</span> HVXInputData *InputParams,
                <span style="color: blue">const</span> HVXDSPConfig *adspConfig,
                INT*  handle);

        <span style="color: darkgreen">/**
         * HVXDestroy
         *
         * @brief  This method destroys the derived instance of the interface
         *
         * @param  pCHIISPHVXAlgorithm   Pointer to CHIISPHVXAlgorithm instance
         *
         * @return CDKResultSuccess upon success.
         */</span>
        CDKResult (*pHVXDestroy)(<span style="color: blue">void</span> *oem_data);

} CHIISPHVXALGORITHMCALLBACKS;
</pre><p>
<b>Session Configuration:</b>
</p><pre><span style="color: darkgreen">/// @brief HVXResolutionInfo</span>
<span style="color: blue">typedef</span> <span style="color: blue">struct</span>
{
    UINT          sensorWidth;  <span style="color: darkgreen">//  [INPUT] sensor output width</span>
    UINT          sensorHeight; <span style="color: darkgreen">//  [INPUT] sensor output height</span>
    HVXTapPoint   tappingPoint; <span style="color: darkgreen">//  [INPUT]tap point</span>
    UINT          outputFormat; <span style="color: darkgreen">//  [INPUT] hvx output format</span>
    UINT          hvxOutWidth;  <span style="color: darkgreen">//  [OUTPUT] HVX output width</span>
    UINT          hvxOutHeight; <span style="color: darkgreen">//  [OUTPUT] HVX output height</span>
}HVXResolutionInfo;

<span style="color: darkgreen">/// @brief HVXGetSetInfo</span>
<span style="color: blue">typedef</span> <span style="color: blue">struct</span>
{
  UINT availableHVXUnits;       <span style="color: darkgreen">//  [INPUT] currently available hvx units</span>
                            <span style="color: darkgreen">//  on DSP side(1 / 2 / 3 / 4)</span>
  HVXVectorMode availableHVXVectorMode; <span style="color: darkgreen">//  [INPUT] currently available hvx vector mode</span>
  UINT availableL2Size;                         <span style="color: darkgreen">//  [INPUT] available L2 cache size</span>
  BOOL isStatsNeeded;                           <span style="color: darkgreen">//  [INPUT]Stats data needed.</span>
  UINT hvxEnable;                               <span style="color: darkgreen">//  [OUTPUT] enable / disable HVX for current configuration</span>
  <span style="color: blue">char</span> algorithmName[32];                       <span style="color: darkgreen">//  [OUTPUT] algorithm name to run on ADSP</span>
  UINT requestHVXUnits;                         <span style="color: darkgreen">//  [OUTPUT] hvx units to be used for this sensor</span>
  HVXVectorMode requestHVXVectorMode;   <span style="color: darkgreen">//  [OUTPUT] HVX vector mode to be used for this sensor</span>
  UINT kernelSize;                              <span style="color: darkgreen">//  [OUTPUT] Kernel size for Dual IFE calculation</span>
} HVXGetSetInfo;
</pre><p>
<b>Callback Functrions (implement in OEM Skel:</b>
</p><pre><span style="color: darkgreen">/** 
 * app_callbac_functns_t
 *
 * @brief  Structure containing pointers to callback functions implemented by the app.
 */</span>

<span style="color: blue">typedef</span> <span style="color: blue">struct</span> app_callbac_functns {
    fp_get_config_t     get_config_func_ptr;            <span style="color: darkgreen">//Framework will call this to obtain configuration data.</span>
    fp_process_lines_t  process_lines_func_ptr; <span style="color: darkgreen">// Framework will call this to process a given number of lines.</span>
    fp_work_loop_t      work_loop_func_ptr;                     <span style="color: darkgreen">// Framework will call this to start a custom workloop in a separate thread.</span>
    fp_app_exit_t       exit_func_ptr;                          <span style="color: darkgreen">// Framework will call this at termination stage.</span>
    }app_callbac_functns_t;
</pre><p>
<b>External fastRPC Interface:</b>
</p><pre><span style="color: darkgreen">/** 
 * dsp_streamer_open()
 * Open fastRPC session.
 * Opens the handle in the specified domain.  If this is the first
 * handle, this creates the session.  Typically this means opening
 * the device, aka open("/dev/adsprpc-smd"), then calling ioctl
 * device APIs to create a PD on the DSP to execute our code in,
 * then asking that PD to dlopen the .so and dlsym the skel function.
 */</span>
<span style="color: blue">int</span> dsp_streamer_open(<span style="color: blue">const</span> <span style="color: blue">char</span>* uri, remote_handle64* handle);

<span style="color: darkgreen">/** 
 * dsp_streamer_close()
 * Close fastRPC session.
 * Closes a handle.  If this is the last handle to close, the session
 * is closed as well, releasing all the allocated resources.
 */</span>
<span style="color: blue">int</span> dsp_streamer_close(remote_handle64 handle);

<span style="color: darkgreen">/** 
 * dsp_streamer_event()
 * signal one of various events to the DSP together with the corresponding
 * data (if any)
 * @hvx_event_type_t type:
 *       HVX_EVENT_OPEN -&gt; Open a streaming session
 *       HVX_EVENT_STATIC_CONFIG -&gt; Static configuration related to input 
 *       HVX_EVENT_DYNAMIC_CONFIG -&gt; Algorithm-specific and per-frame control 
 *                                                               parameters
 *       HVX_EVENT_START -&gt; Start streamer
 *       HVX_EVENT_RESET -&gt; Reset streamer to initial unconfigured states
 *       HVX_EVENT_STOP  -&gt; Stop streamer
 *       HVX_EVENT_CLOSE -&gt; Close streamer session
 */</span>
<span style="color: blue">int</span> dsp_streamer_event(
        remote_handle64 _h,
        <span style="color: blue">int</span> *handle,
        hvx_event_type_t type,
        <span style="color: blue">const</span> <span style="color: blue">char</span> *data,
        <span style="color: blue">int</span> dataLen);
</pre><p>
<b>Static Configuration:</b>
</p><pre><span style="color: blue">struct</span> hvx_static_config_t {
   tapping_point_select_t tapping_point;<span style="color: darkgreen">//IFE tapping point</span>
   hvx_IFE_mode_t IFE_mode;             <span style="color: darkgreen">//IFE mode (single, dual IFE etc)</span>
   <span style="color: blue">int</span> hvx_unit_no[2];                  <span style="color: darkgreen">//IFE unit used for each slot</span>
   <span style="color: blue">int</span> in_width;                        <span style="color: darkgreen">//Input resolution: width in pixels</span>
   <span style="color: blue">int</span> in_height;                               <span style="color: darkgreen">//Input resolution: height in pixels</span>
   <span style="color: blue">int</span> image_overlap;                   <span style="color: darkgreen">//Overlap for dual-IFE mode</span>
   <span style="color: blue">int</span> right_image_offset;              <span style="color: darkgreen">//Offset for dual-IFE mode</span>
   <span style="color: blue">int</span> out_width;                       <span style="color: darkgreen">//Output resolution: width in pixels</span>
   <span style="color: blue">int</span> out_height;                      <span style="color: darkgreen">//Output resolution: height in pixels</span>
   hvx_pixel_format_t pixel_format;     <span style="color: darkgreen">//Pixel format</span>
   <span style="color: blue">int</span> bits_per_pixel;                  <span style="color: darkgreen">//Number of bits in each pixel</span>
   <span style="color: blue">unsigned</span> <span style="color: blue">int</span> ife_clk_freq[2];        <span style="color: darkgreen">//IFE clock</span>
   <span style="color: blue">int</span> IFE_id;                          <span style="color: darkgreen">//Identifies the sender of this data</span>

   hvx_vector_mode_t hvx_vector_mode;   <span style="color: darkgreen">//HVX mode</span>
   request_buffer_t req_buf[2];                 <span style="color: darkgreen">//deprecated</span>
   buf_request_mode_t buf_request_mode; <span style="color: darkgreen">//deprecated</span>
};
</pre><h3>
<a name="QDSP6%20lib%20API"></a>QDSP6 lib API
</h3><p>
QDSP6 lib is the main software module that does the pixel processing during camera streaming. User needs to implement two functions in this library: configuration and processing.
</p><p>
Configuration function will talk to camera streaming framework and configure algorithm specific parameters including input/output buffer size, padding, etc. This is one-time call before streaming starts.
</p><p>
Processing function contains the bulks of algorithm details and is usually computationally intensive. Once the function is invoked, the QDSP6 lib will be in a infinite loop, waiting to process pixel data. All start/stop and update commands will be sent through a special communication buffer, which will be discussed in later sections.
</p><p>
QDSP6 lib's processing has to stick to very specific timing to be in-sync with ISP's timing. To facilitate that, a set of utility functions are provided by camera streaming framework.
</p><pre><span style="color: darkgreen">/**
 * @brief app_entry()
 *
 * This is the entry point how the user component been register onto streamer framework 
 * verison number as a string. 
 *
 * @param:
 *      app_callbacks_p-&gt;get_config_func_ptr -&gt; function pointer to streamer configuratio from user 
 *      app_callbacks_p-&gt;process_lines_func_ptr -&gt; function pointer to pre-process algo from user
 *      app_callbacks_p-&gt;exit_func_ptr -&gt; function pointer to terminate streamer process from user
 *      app_callbacks_p-&gt;work_loop_func_ptr -&gt; function pointer the the process workloop if user want to control it 
 *                                              or else set to NULL (streamer framework will control the workloop)
 * @return None 
 */</span>
<span style="color: blue">void</span> app_entry(app_callbac_functns_t *app_callbacks_p, <span style="color: blue">void</span>** app_context_pp, <span style="color: blue">void</span> *client_p, framework_callback_functns_t *fwk_callbacks_p)
{
    FARF(ALWAYS, <span style="color: darkred">"%s: E"</span>, __func__);
    *app_context_pp = malloc(<span style="color: blue">sizeof</span>(hvx_add_constant_context_t));
    ((hvx_add_constant_context_t*)(*app_context_pp))-&gt;client_p = client_p;
    ((hvx_add_constant_context_t*)(*app_context_pp))-&gt;callbacks_p = fwk_callbacks_p;

<span style="color: darkgreen">//////////////////////////////////////////////////</span>
<span style="color: darkgreen">// User need to populate these function pointer //</span>
<span style="color: darkgreen">//////////////////////////////////////////////////</span>
    app_callbacks_p-&gt;get_config_func_ptr =  &amp;hvx_add_constant_get_config;
    app_callbacks_p-&gt;process_lines_func_ptr = &amp;hvx_add_constant_process_lines;
    app_callbacks_p-&gt;exit_func_ptr = &amp;hvx_add_constant_terminate;
<span style="color: blue">#ifdef</span> USE_CUSTOM_WORKLOOP <span style="color: darkgreen">//define if user want to control workloop</span>
    app_callbacks_p-&gt;work_loop_func_ptr = &amp;hvx_add_constant;
<span style="color: blue">#else</span>
    app_callbacks_p-&gt;work_loop_func_ptr = NULL;
<span style="color: blue">#endif</span>

    FARF(ALWAYS, <span style="color: darkred">"%s: X"</span>, __func__);
}

<span style="color: darkgreen">/**
 * @brief: app_callbacks_p-&gt;get_config_func_ptr = &amp;hvx_add_constant_get_config;
 * This function allows User to configure the streamer accordingly to User's requirement
 * (RX/TX buffer size, n of capture lines, how to pack onto L2$ buffer pixel data padding etc..)
 *
 * @param  app_context_p   Pointer to app context allocate at entry point.
 * @param config_in_p: pointer to the (input) configuration data set by the streamer framework (configuration from the IFE side).
 * @param config_out_p: pointer to the (output) configuration data set by the User and returned to the streamer framework.
 * @return If success, return HVX_SUCCESS.
 */</span>
<span style="color: blue">int</span> hvx_add_constant_get_config(<span style="color: blue">void</span> *app_context_p,
        config_from_client_t* config_in_p,
        config_from_app_t* config_out_p);

<span style="color: darkgreen">/**
 * @brief: app_callbacks_p-&gt;process_lines_func_ptr = &amp;hvx_add_constant_process_lines;
 * This is User's Pre-process function
 *
 * @param  app_context_p   Pointer to app context allocate at entry point.
 * @param  dst_p -&gt; point to output buffer for Algo to write to
 * @param  src_p -&gt; pointer to input buffer where pixel data been captured for Algo to read from
 * @param  params_p -&gt; useful param to Algo
 * @return None
 */</span>
<span style="color: blue">void</span> hvx_add_constant_process_lines(
        <span style="color: blue">void</span> *app_context_p,
        <span style="color: blue">void</span>* dst_p,
        <span style="color: blue">void</span>* src_p,
        process_lines_params_t* params_p);
</pre><p>
<b>Optional: if User want to control the workloop</b>
</p><p>
This set of API will allow User to control the workloop.
</p><pre><span style="color: darkgreen">/**
 * @brief get raw status of current streamer
 *
 * @param dev_p: pointer to streamer device.
 *
 * @return unsigned int: RAW_STATUS register value, refer to below chart for error bits detail
 */</span>
uint32_t process_util_get_streamer_raw_status(<span style="color: blue">void</span> *dev_p);
uint32_t process_util_get_error_status_mask(<span style="color: blue">void</span> *dev_p);
uint32_t process_util_get_RX_bad_frame_error_status_mask(<span style="color: blue">void</span> *dev_p);
</pre><left><img src="images/error_status.png"></left><pre><span style="color: darkgreen">/**
 * @brief get framework version
 *
 * This function will return the HVX camera streaming framework 
 * verison number as a string. 
 *
 * @param v output string of version number 
 * @return None 
 */</span>
<span style="color: blue">void</span> get_framework_version(<span style="color: blue">char</span>* v);

<span style="color: darkgreen">/**
 * Function: process_util_get_streamer_status()
 * @brief get status of currnt streamer
 *
 * @param dev_p: pointer to streamer device.
 *
 * @return unsigned int: STATUS register value
 */</span>
uint32_t process_util_get_streamer_status(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_set_status_mask()
 * @brief set SOL and SOF bit in STATUS register, configure this 
 *        for interrupts
 *
 * @param dev_p: pointer to streamer device.
 *
 * @return None
 */</span>
<span style="color: blue">void</span> process_util_set_status_mask(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_check_reg_update()
 *
 * Arguments:
 * @param dev_p: pointer to streamer device.
 *
 * Description:
 *     check if REG_UPDATE bit is set
 *
 * Return Value:
 *     0: bit not set
 *     1: bit set
 */</span>
uint32_t process_util_check_reg_update(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_update_metabuf()
 *
 * Arguments:
 *     @arg dev_p: pointer to device context.
 *
 * Description:
 *     copy shadow CX content to CX
 *
 * Return Value:
 *     see process_util_err_type
 */</span>
<span style="color: blue">int</span> process_util_update_metabuf(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_get_start_flag()
 *
 * Arguments:
 *     @arg dev_p: pointer to device context.
 *     @arg start_flag: return value, 0 means not set, 1 means
 *          start flag set, ready to start
 *
 * Description:
 *     return start flag set by control thread
 *
 * Return Value:
 *     see process_util_err_type
 */</span>
uint32 process_util_get_start_flag(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_get_&lt;&gt;_flag()
 *
 * Arguments:
 *     @arg dev_p: pointer to device context.
 *
 * Description:
 *     return flag set by control thread
 *
 * Return Value:
 *     1: exit
 *     0: do not exit
 */</span>
uint32 process_util_get_force_exit_flag(<span style="color: blue">void</span> *dev_p);

uint32 process_util_get_dump_flag(<span style="color: blue">void</span> *dev_p);

uint32 process_util_get_stats_flag(<span style="color: blue">void</span> *dev_p);


<span style="color: darkgreen">/**
 * Function: process_util_get_metabuf()
 *     @arg dev_p: pointer to device context.
 *
 * Description:
 *     return value of metabuf pointer
 *
 * Return void*:
 */</span>
<span style="color: blue">void</span> * process_util_get_metabuf(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_get_rxbuf_addr
 *     @arg dev_p: pointer to device context.
 *
 * Description:
 *     return address pointer of RX circular buffer
 *
 * Return void*:
 */</span>
<span style="color: blue">void</span> * process_util_get_rxbuf_addr(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_get_txbuf_addr
 *     @arg dev_p: pointer to device context.
 *
 * Description:
 *     return address pointer of TX circular buffer
 *
 * Return void*:
 */</span>
<span style="color: blue">void</span> * process_util_get_txbuf_addr(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_check_rx_&lt;&gt;()
 *
 * Arguments:
 * @param dev_p: pointer to streamer device.
 *
 * Description:
 *     Check if &lt;&gt; bit got updated in STATUS register
 *
 * Return Value:
 *     1: &lt;&gt; bit set
 *     0: &lt;&gt; bit not set
 */</span>
uint32_t process_util_check_rx_sof(<span style="color: blue">void</span> *dev_p);

uint32_t process_util_check_rx_sol(<span style="color: blue">void</span> *dev_p);

uint32_t process_util_check_rx_eol(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_reset_rx_&lt;&gt;()
 *
 * Arguments:
 * @param dev_p: pointer to streamer device.
 *
 * Description:
 *     Reset &lt;&gt; bit to 0 in STATUS register
 *
 * Return Value:
 *     None
 */</span>
<span style="color: blue">void</span> process_util_reset_rx_sof(<span style="color: blue">void</span> *dev_p);
<span style="color: blue">void</span> process_util_reset_rx_sol(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_rx_wait_for_line()
 *
 * Arguments:
 * @param dev_p: pointer to streamer device.
 * @param linecount: waiting period (in num. of lines).
 *
 * Description:
 *     Wait until rx get linecount+1 lines(EOLs)
 *     eg: wait until RX_LINE_COUNT register reach linecount+1
 *
 * Return Value:
 *     linecount+1
 */</span>
uint32_t process_util_rx_wait_for_line(<span style="color: blue">void</span> *dev_p, uint32_t linecount);

<span style="color: darkgreen">/**
 * Function: process_util_rx_done()
 *
 * Arguments:
 * @param dev_p: pointer to streamer device.
 * @arg offset: offset of consumed data in rx
 *
 * Description:
 *     Update RX_INDEX_CONSUMED register to offset
 *
 * Return Value:
 *     None
 */</span>
<span style="color: blue">void</span> process_util_rx_done(<span style="color: blue">void</span> *dev_p, uint32_t offset);

<span style="color: darkgreen">/**
 * Function: process_util_rx_done()
 *
 * Arguments:
 * @param dev_p: pointer to streamer device.
 * @arg offset: offset of transmit data in tx
 *
 * Description:
 *     Update TX_INDEX_AVAIL register to offset
 *
 * Return Value:
 *     None
 */</span>
<span style="color: blue">void</span> process_util_tx_done(<span style="color: blue">void</span> *dev_p, uint32_t offset);

<span style="color: darkgreen">/**
 * Function: process_util_tx_wait_for_eof()
 *
 * Arguments:
 * @param dev_p: pointer to streamer device.
 *
 * Description:
 *     wait until EOF bit got set in STATUS register
 *
 * Return Value:
 *     None
 */</span>
<span style="color: blue">void</span> process_util_tx_wait_for_eof(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_tx_clear_eof()
 *
 * Arguments:
 * @param dev_p: pointer to streamer device.
 *
 * Description:
 *     reset EOF bit to 0 in STATUS register
 *
 * Return Value:
 *     None
 */</span>
<span style="color: blue">void</span> process_util_tx_clear_eof(<span style="color: blue">void</span> *dev_p);

<span style="color: darkgreen">/**
 * Function: process_util_recover_streamer()
 *
 * Arguments:
 * @param dev_p: pointer to streamer device.
 *
 * Description:
 *     in case of overflow happens, call this function which
 *     will do:
 *       stop streamer
 *       reset streamer
 *       reprogram streamer with previous values
 *       start streamer
 *
 * Return Value:
 *     none
 */</span>
<span style="color: blue">void</span> process_util_recover_streamer(<span style="color: blue">void</span> *dev_p);


uint32_t process_util_get_rx_lines(<span style="color: blue">void</span> *dev_p);

<span style="color: blue">void</span>* process_util_get_streamer_config(<span style="color: blue">void</span> *dev_p);

<span style="color: blue">void</span>* process_util_get_frame_info(<span style="color: blue">void</span> *dev_p);

<span style="color: blue">void</span>* process_util_get_config_from_app(<span style="color: blue">void</span> *dev_p);

<span style="color: blue">void</span>* process_util_get_client_cfg(<span style="color: blue">void</span> *dev_p);

<span style="color: blue">void</span>* process_util_get_app_context(<span style="color: blue">void</span> *dev_p);
</pre><p>
This API could be out-of-date. Please refer to this file in latest SDK release: . &lt;hexagonSDK root&gt;/3.x/lib/camera_streaming/framework/ship/hexagon_ReleaseG_dynamic_toolv83_v66/sm8250_sm7250/
</p><p>
To see the usage of OEM plugin API, please refer to these examples:
</p><pre>&lt;platform&gt;/vendor/qcom/proprietary/camx/chi-cdk/vendor/node/hvx/addconstant
</pre><p>
To see the usage of QDSP6 lib API, please refer to these examples:
</p><pre>&lt;hexagonSDK root&gt;/3.x/examples/camera_streaming/hvx_add_constant
</pre><h2>
<a name="Communication%20and%20buffers"></a>Communication and buffers
</h2><p>
For camera streaming use case, there is no system memory buffer used, with the exception that QDSP6 output some meta data directly to system memory. All operations are done in QDSP6's L2 cache to cope with camera streaming's high requirement on duty cycle. For this purpose, camera streaming framework provides mechanism to lock 256K byte of QDSP6's L2 cache. Once locked, this portion of cache will not be visible to any other process on QDSP6.
</p><p>
The locked QDSP6's L2 cache is mainly partitioned to three types of buffers: Receiving buffer (RX); Transmission buffer (TX) and Communication buffer (CX).
</p><h3>
<a name="Receiving%20buffer%20(RX)"></a>Receiving buffer (RX)
</h3><p>
Receiving buffer is used to receive input pixel data from ISP's pixel interface. This latency buffer has only limited size, so that RX overflow would occur if the speed of QDSP6's fetching from RX is slower than speed of streaming, which is fatal.
</p><h3>
<a name="Transmission%20buffer%20(TX)"></a>Transmission buffer (TX)
</h3><p>
Transmission buffer is used to store QDSP6 processed data before they are sent back to ISP's pixel interface. If QDSP6 produces data slower than HVX streaming module's read speed, a TX underflow will be reported as warning.
</p><h3>
<a name="Communication%20buffer%20(CX)"></a>Communication buffer (CX)
</h3><p>
Communication buffer is used to store flags and parameter updates between user lib and QDSP6 lib to avoid the function call overhead, which might slow down QDSP6's processing speed and lead to buffer over-run or under-run. These flags and updates make camera streaming start/stop or change behavior. The CX buffer is shadowed, meaning any update to this buffer will take effect on the next frame.
</p><p align="center" style="display:block;padding-top: 50px;">
  Copyright &#169; 2018 Qualcomm Technologies Inc. All rights reserved.

</p><a style="display:block;padding-bottom: 700px;"></a></div></div>
</body>
</html>
